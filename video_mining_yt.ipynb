{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_mining_yt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doubleblindreview2/jbr_video_mining/blob/master/video_mining_yt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW5CvsYJskRb",
        "colab_type": "text"
      },
      "source": [
        "# **JBR Video Mining Script**\n",
        "- **Output**: This script extracts various video features from a given set of videos and stores these features in multiple .csv files, which can be opened with Excel or any text editor afterwards\n",
        "- **Input**: You need to provide a Google Drive Account with a folder with video files\n",
        "- **Execution**: In order to execute this script, run all cells from top to bottom and follow the instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okoFRhcK7n-d",
        "colab_type": "text"
      },
      "source": [
        "Before you start:  **<font color='red'>Please click -> Runtime -> Change runtime type -> GPU in top menu</font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIk0EgQ8Xbuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'amos' # change to jochen or jasper\n",
        "num = 0       # change to 1 for second and 2 for third notebook "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fHqjvh9mS82",
        "colab_type": "text"
      },
      "source": [
        "## **1. Download Models**\n",
        "_You need a Google Account to verify your legitimate use; The models will be automatically downloaded from a public GDrive_\n",
        "_____________________________________________________________________________\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUUG2Emgx_ET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkvXvCwDhBlU",
        "colab_type": "text"
      },
      "source": [
        "Running the next cell will create a link. **You need to click this link and enter your Google Account credentials. Copy the code and enter it in the space below.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhD5gLYbzkOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdNhcxUim2ta",
        "colab_type": "text"
      },
      "source": [
        "Running the next cell will download required models from a public GDrive. After running it, you can verify success by clicking on the folder icon on the left side of this screen.There should be a 'downloads' folder containing various files (You may need to click 'Refresh')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2hky3wJF17G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('/content/downloads/'): os.makedirs('/content/downloads/')\n",
        "os.chdir('./downloads/')\n",
        "\n",
        "folder_id = '1e-UQc-ylzVOOvW2ZiOCpnP-EEziHA4cQ'\n",
        "file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(folder_id)}).GetList()\n",
        "for file in tqdm(file_list):\n",
        "    file.GetContentFile(file['title'])\n",
        "\n",
        "os.chdir('/content/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f_8XH-Bmmee",
        "colab_type": "text"
      },
      "source": [
        "## **2. Provide Input & Select Features**\n",
        "_You need to provide a Google Drive Account, which includes a folder with video files for video mining._\n",
        "_____________________________________________________________\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1G3nRSNiHPi",
        "colab_type": "text"
      },
      "source": [
        "Running the next cell will create a link. **You need to click this link and enter your Google Account credentials. Copy the code and enter it in the space below.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Icp9RCnAYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPuhPlnK3od3",
        "colab_type": "text"
      },
      "source": [
        "## **2.1 Get YT Vids**\n",
        "_Simply run all cells._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAgzgS6ADY6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqiNFkGo5MTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q youtube-dl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjGNmbgM4GR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('/content/yt_vids/'): \n",
        "  os.mkdir('/content/yt_vids/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCyx1FbYBcK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yt_ids = pd.read_csv(f'/content/drive/My Drive/trailer/vids/batch_{name}_{num}.csv',index_col = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKf7O-9etjmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extract_length           = False # get length of video\n",
        "extract_cuts             = False # get scene cuts\n",
        "extract_colors           = False # get brightness and  color information\n",
        "extract_faces            = False # get faces\n",
        "extract_emotions         = True # get 8 different emotions per face \n",
        "extract_objects          = False # get 80 objects\n",
        "extract_variance         = True # get semantic variance\n",
        "extract_quality          = False # get quality\n",
        "\n",
        "in_folder  = '/content/yt_vids/'  # folder with videos, names are used as IDs\n",
        "out_folder = '/content/drive/My Drive/trailer/preds/' # folder to store extracted features\n",
        "\n",
        "device = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1pu3v5moBx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for YOUTUBE_ID in list(yt_ids.yt_id):\n",
        "  if not YOUTUBE_ID+'.mp4' in os.listdir('/content/yt_vids/'):\n",
        "    !youtube-dl -f 'bestvideo[ext=mp4]' --output \"/content/yt_vids/\"$YOUTUBE_ID\".%(ext)s\" https://www.youtube.com/watch?v=$YOUTUBE_ID\n",
        "\n",
        "log_name   = f'2020-05-23_logfile_{start}.csv' # name of lofile, pls include .csv ending \n",
        "log_folder = '/content/drive/My Drive/trailer/logs/' # folder for logfile\n",
        "\n",
        "start_index = 0\n",
        "end_index = len(os.listdir(in_folder))\n",
        "\n",
        "# device number of GPU, do not change and set Runtime Type to GPU\n",
        "variables = ''\n",
        "for variable in ['extract_length',\n",
        "                'extract_cuts',\n",
        "                'extract_colors',\n",
        "                'extract_faces',\n",
        "                'extract_emotions',\n",
        "                'extract_variance',\n",
        "                'extract_objects',\n",
        "                'extract_quality',\n",
        "                'start_index',\n",
        "                'end_index',\n",
        "                'device']:\n",
        "  variables += ' --' + variable.replace('_','-') + ' ' + str(eval(variable))\n",
        "\n",
        "for variable in ['in_folder',\n",
        "                'out_folder',\n",
        "                'log_folder',\n",
        "                'log_name']:\n",
        "  variables += ' --' + variable.replace('_','-') + ' \"' + str(eval(variable))+'\"'\n",
        "\n",
        "!python \"/content/downloads/jbr_run.py\" {variables}\n",
        "\n",
        "# shutil.rmtree('/content/scene_imgs')\n",
        "# for i in os.listdir('/content/yt_vids'):\n",
        "#   !rm -rf \"/content/yt_vids/\"$i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpRPdkr6YTwB",
        "colab_type": "text"
      },
      "source": [
        "# **<font color='red'>Thanks, that's it!!!</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S84YwhciPYP",
        "colab_type": "text"
      },
      "source": [
        "**Please provide the correct pathes to your folder with videos. You probably need to change the text after '/My Drive/**.\n",
        "\n",
        "You can verify the correct path by clicking on the folder icon on the left side of this screen and search within the 'drive' folder. (You may need to click 'Refresh') "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xc6ul7ETY2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "in_folder  = '/content/drive/My Drive/trailer/vids/'  # folder with videos, names are used as IDs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJuuNBDUkGee",
        "colab_type": "text"
      },
      "source": [
        "You **can unselect features** you are not interested in **by writing 'False' instead of 'True'**. This may drastically increase processing speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BR9d_Kvui7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extract_length           = False # get length of video\n",
        "extract_cuts             = False # get scene cuts\n",
        "extract_colors           = False # get brightness and  color information\n",
        "extract_faces            = False # get faces\n",
        "extract_emotions         = True # get 8 different emotions per face \n",
        "extract_objects          = False # get 80 objects\n",
        "extract_variance         = True # get semantic variance\n",
        "extract_quality          = False # get quality"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnI2Vu0djci4",
        "colab_type": "text"
      },
      "source": [
        "## **4. Provide Optional Input**\n",
        "_**Run all cells - no additional input required, however you may change things to customize execution**_\n",
        "_____________________________________________________________\n",
        "\n",
        "The following folders and the logfile will be created to store the results of your analysis. **You do not have to change them, unless you want to use your custom folder** structure to store results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "505rRLPFjeGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_folder = '/content/drive/My Drive/trailer/preds/' # folder to store extracted features\n",
        "log_name   = '2020-05-23_logfile.csv' # name of lofile, pls include .csv ending \n",
        "log_folder = '/content/drive/My Drive/trailer/logs/' # folder for logfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXdB63WE40CN",
        "colab_type": "text"
      },
      "source": [
        "Setting a start and end index allows you to only analyze a subset of the videos in your folder. **You do not have to change this, if you want to analyze all videos in your provided folder.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNLRRRV_40K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_index = 0\n",
        "end_index = len(os.listdir(in_folder))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm1B0xoq4BXn",
        "colab_type": "text"
      },
      "source": [
        "The following code tells the code to use the GPU if required.  **You do not have to change this.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vCg1anq4APJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYU3L3SU4h4m",
        "colab_type": "text"
      },
      "source": [
        "## **4. Extract Selected Features**\n",
        "_**Run all cells - no additional input required**_\n",
        "\n",
        "_This will extract your selected features by looping through your provided video files folder. (This may take siginificant amount of time)._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sopyJEtc3fIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # device number of GPU, do not change and set Runtime Type to GPU\n",
        "variables = ''\n",
        "for variable in ['extract_length',\n",
        "                 'extract_cuts',\n",
        "                 'extract_colors',\n",
        "                 'extract_faces',\n",
        "                 'extract_emotions',\n",
        "                 'extract_variance',\n",
        "                 'extract_objects',\n",
        "                 'extract_quality',\n",
        "                 'start_index',\n",
        "                 'end_index',\n",
        "                 'device']:\n",
        "  variables += ' --' + variable.replace('_','-') + ' ' + str(eval(variable))\n",
        "\n",
        "for variable in ['in_folder',\n",
        "                 'out_folder',\n",
        "                 'log_folder',\n",
        "                 'log_name']:\n",
        "  variables += ' --' + variable.replace('_','-') + ' \"' + str(eval(variable))+'\"'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnUnsUD16EN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variables"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPrqCL5136LT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python \"/content/downloads/jbr_run.py\" {variables}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bQO_ws-IUdw",
        "colab_type": "text"
      },
      "source": [
        "# ONLY TESTS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvvdEkQzm7aR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from zipfile import ZipFile\n",
        "import sys\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "import cv2\n",
        "from os.path import isfile, join\n",
        "import datetime as dt\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from keras.preprocessing import image\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18nDOk2QmfIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  input_path = '/content/yt_vids/Xr_N3-kF2hk.mp4'\n",
        "  out_path = '/content/yt_vids/4'\n",
        "  name = 'Xr_N3-kF2hk'\n",
        "  skip_frames=20\n",
        "\n",
        "\n",
        "# def get_emotions(input_path, out_path, name, skip_frames=10):\n",
        "  # read video file\n",
        "  cap = cv2.VideoCapture(input_path)\n",
        "  \n",
        "  # load preconfigured model and precomputed weights\n",
        "  model = model_from_json(open(\"/content/downloads/facial_expression_model_structure.json\", \"r\").read())         ## REQUIRED TO CHANGE PATH\n",
        "  model.load_weights('/content/downloads/facial_expression_model_weights.h5')                                    ## REQUIRED TO CHANGE PATH\n",
        "  face_cascade = cv2.CascadeClassifier('/content/downloads/haarcascade_frontalface_default.xml')    ## REQUIRED TO CHANGE PATH\n",
        "  \n",
        "  df = pd.DataFrame(columns=['TimeStamp','Frame','Number of Faces (left->right)','Face Position','angry','disgust','fear','happy','sad','surprise','neutral'])\n",
        "  \n",
        "  try:\n",
        "      i = 0\n",
        "      while (cap.isOpened()):\n",
        "          # cap.read() -> checks whether or not frame has been read correctly. Returns boolean value\n",
        "          ret, frame = cap.read()\n",
        "          if not (ret):\n",
        "              break\n",
        "  \n",
        "          # for every x frame\n",
        "          if cap.get(cv2.CAP_PROP_POS_FRAMES) % skip_frames == 0:\n",
        "              gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "              faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "  \n",
        "              face_counter = 0\n",
        "              \n",
        "              for (x, y, w, h) in faces:\n",
        "                  # cuts frames into required data (requires 4-Dim instead of 3, therefore i used the given approach from the project)\n",
        "                  cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "                  detected_face = frame[int(y):int(y + h), int(x):int(x + w)]  # crop detected face\n",
        "                  detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY)  # transform to gray scale\n",
        "                  detected_face = cv2.resize(detected_face, (48, 48))  # resize to 48x48\n",
        "                  img_pixels = image.img_to_array(detected_face)\n",
        "                  img_pixels = np.expand_dims(img_pixels, axis=0)/255\n",
        "  \n",
        "                  # prediction\n",
        "                  predictions = model.predict(img_pixels)\n",
        "\n",
        "                  df.loc[i,'TimeStamp'] = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "                  df.loc[i,'Frame'] = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "                  df.loc[i,'Number of Faces (left->right)'] = len(faces)\n",
        "                  df.loc[i,'Face Position'] = face_counter\n",
        "                  df.loc[i,'angry':] = pd.Series(predictions[0],index=df.loc[:,'angry':].columns)\n",
        "\n",
        "                  face_counter += 1\n",
        "                  i +=1\n",
        "\n",
        "      # When everything done, release the capture\n",
        "      cap.release()\n",
        "      cv2.destroyAllWindows\n",
        "\n",
        "      df.to_csv(out_path + name + '_FrameLevel_emotions.csv')\n",
        "      pd.concat([df.loc[:,'angry':].mean(),df.loc[:,'angry':].max()],axis=1).rename(columns={0:'Average',1:'Max'}).to_csv(out_path + name + '_VideoLevel_emotions.csv')\n",
        "  \n",
        "      print(df.head())\n",
        "  except:\n",
        "      print(sys.exc_info()[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0GqVla9IYNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = get_emotions('/content/yt_vids/10r9ozshGVE.mp4','/content/drive/My Drive/trailer/preds/5MBjAN7jqsQ/','5MBjAN7jqsQ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nCf6-q2eaj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()\n",
        "pd.DataFrame(df.loc[:,'angry':].mean(),columns=['Average'])\n",
        "vl = pd.concat([df.loc[:,'angry':].mean(),df.loc[:,'angry':].max()],axis=1).rename(columns={0:'Average',1:'Max'})\n",
        "# vl.columns=['Average','Max']\n",
        "vl\n",
        "# df.loc[:,'angry':].max()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OC7CuLeYs9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 100\n",
        "a/=10\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKgIosFLSGH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emotions(input_path, out_path, name, skip_frames=10):\n",
        "  # read video file\n",
        "  cap = cv2.VideoCapture(input_path)\n",
        "  \n",
        "  # load preconfigured model and precomputed weights\n",
        "  model = model_from_json(open(\"/content/downloads/facial_expression_model_structure.json\", \"r\").read())         ## REQUIRED TO CHANGE PATH\n",
        "  model.load_weights('/content/downloads/facial_expression_model_weights.h5')                                    ## REQUIRED TO CHANGE PATH\n",
        "  face_cascade = cv2.CascadeClassifier('/content/downloads/haarcascade_frontalface_default.xml')    ## REQUIRED TO CHANGE PATH\n",
        "  \n",
        "  df = pd.DataFrame(columns=['TimeStamp','Frame','Number of Faces (left->right)','Face Position','angry','disgust','fear','happy','sad','surprise','neutral'])\n",
        "  \n",
        "  try:\n",
        "      i = 0\n",
        "      while (cap.isOpened()):\n",
        "          # cap.read() -> checks whether or not frame has been read correctly. Returns boolean value\n",
        "          ret, frame = cap.read()\n",
        "          if not (ret):\n",
        "              break\n",
        "  \n",
        "          # for every x frame\n",
        "          if cap.get(cv2.CAP_PROP_POS_FRAMES) % skip_frames == 0:\n",
        "              gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "              faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "  \n",
        "              face_counter = 0\n",
        "              \n",
        "              for (x, y, w, h) in faces:\n",
        "                  # cuts frames into required data (requires 4-Dim instead of 3, therefore i used the given approach from the project)\n",
        "                  cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "                  detected_face = frame[int(y):int(y + h), int(x):int(x + w)]  # crop detected face\n",
        "                  detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY)  # transform to gray scale\n",
        "                  detected_face = cv2.resize(detected_face, (48, 48))  # resize to 48x48\n",
        "                  img_pixels = image.img_to_array(detected_face)\n",
        "                  img_pixels = np.expand_dims(img_pixels, axis=0)/255\n",
        "  \n",
        "                  # prediction\n",
        "                  predictions = model.predict(img_pixels)\n",
        "\n",
        "                  df.loc[i,'TimeStamp'] = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "                  df.loc[i,'Frame'] = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "                  df.loc[i,'Number of Faces (left->right)'] = len(faces)\n",
        "                  df.loc[i,'Face Position'] = face_counter\n",
        "                  df.loc[i,'angry':] = pd.Series(predictions[0],index=df.loc[:,'angry':].columns)\n",
        "\n",
        "                  face_counter += 1\n",
        "                  i +=1\n",
        "\n",
        "      # When everything done, release the capture\n",
        "      cap.release()\n",
        "      cv2.destroyAllWindows\n",
        "\n",
        "      df.to_csv(out_path + name + '_FrameLevel_emotions.csv')\n",
        "      pd.concat([df.loc[:,'angry':].mean(),df.loc[:,'angry':].max()],axis=1).rename(columns={0:'Average',1:'Max'}).to_csv(out_path + name + 'VideoLevel_emotions.csv')\n",
        "  \n",
        "      return df\n",
        "  except:\n",
        "      return sys.exc_info()[1]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}